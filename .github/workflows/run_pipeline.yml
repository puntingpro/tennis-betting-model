name: Run PuntingPro Full Pipeline

on:
  schedule:
    # Runs every 15 minutes
    - cron: '*/15 * * * *'
  workflow_dispatch: # Allows you to run this workflow manually from the Actions tab

jobs:
  run-live-pipeline:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Authenticate to Google Cloud
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY }}'

      - name: Set up Cloud SDK
        uses: 'google-github-actions/setup-gcloud@v2'

      - name: Download Data and Models from GCS
        run: |
          mkdir -p ./data/processed
          mkdir -p ./models
          gcloud storage cp --recursive gs://puntingpro-data-lucap/processed/* ./data/processed/
          gcloud storage cp --recursive gs://puntingpro-data-lucap/models/* ./models/
        # IMPORTANT: Replace "puntingpro-data-lucap" with your actual bucket name if different

      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run the automation script
        env:
          BF_USER: ${{ secrets.BF_USER }}
          BF_PASS: ${{ secrets.BF_PASS }}
          BF_APP_KEY: ${{ secrets.BF_APP_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        # --- MODIFIED: Run the script as a module ---
        run: python -u main.py automate